#write.table(reference_table,"/Users/ulf.mertens/Desktop/multi_gaussian/toy_examples/reftable_train.csv",row.names=F,col.names=F)
# computing the summary statistics
#summa.train <- matrix(NA, nrow=N, ncol=nbrRes)
#intermed <- solve(crossprod(design)) %*% t(design) # temporary variable
#for(i in 1:N){
#  summa.train[i,1:2] <- intermed %*% y.ref[i,]
#  res <- y.ref[i,] - design %*% summa.train[i,1:2]
#  summa.train[i,3] <- sum(res*res)
#  summa.train[i,4:7] <- c(cov(y.ref[i,], design[,1]),cov(y.ref[i,], design[,2]), cor(y.ref[i,], design[,1]), cor(y.ref[i,], design[,2]))
#  summa.train[i,8:10] <- c(mean(y.ref[i,]), median(y.ref[i,]), var(y.ref[i,]))
#}
#ref.training <- cbind(theta.train, summa.train)
#colnames(ref.training) <- c("beta1", "beta2", "sigma2", "mlBeta1", "mlBeta2","residu2","covyx1","covyx2","coryx1","coryx2","mean","median","var")
#####################################
# Testing set simulation
# as above
theta.test <- matrix(NA, nrow = p, ncol = 3)
theta.test[,3] <- 1/rgamma(p,shape=alpha,rate=beta)
for(i in 1:p){
theta.test[i,1:2] <- rmvnorm(1, rep(0,2), n*theta.test[i,3]*solve(crossprod(design)))
}
y.test <- matrix(NA, nrow=p, ncol=n)
for(i in 1:p){
for(j in 1:n){
y.test[i,j] <- design[j,] %*% theta.test[i,1:2] + rnorm(1,0,sqrt(theta.test[i,3]))
}
intermed1 <- n/(n+1)*solve(crossprod(design)) %*% t(design)
intermed2 <- design %*% solve(crossprod(design)) %*% t(design)
intermed3 <- solve(crossprod(design))
theta1.test.exact <- rep(NA, p)
theta2.test.exact <- rep(NA, p)
theta3.test.exact <- rep(NA, p)
var1.test.exact <- rep(NA, p)
var2.test.exact <- rep(NA, p)
var3.test.exact <- rep(NA, p)
cov12.test.exact <- rep(NA, p)
cov13.test.exact <- rep(0, p)
cov23.test.exact <- rep(0, p)
quant.theta1.test.freq <- matrix(NA, p, 2)
quant.theta2.test.freq <- matrix(NA, p, 2)
quant.theta3.test.freq <- matrix(NA, p, 2)
for(i in 1:p){
theta.test.exact <- intermed1 %*% y.test[i,]
theta1.test.exact[i] <- theta.test.exact[1]
theta2.test.exact[i] <- theta.test.exact[2]
theta3.test.exact[i] <- (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1)
var1.test.exact[i] <- n/(n+1) * intermed3[1,1] * (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] )/(alpha + n/2 -1)
var2.test.exact[i] <- n/(n+1) * intermed3[2,2] * (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] )/(alpha + n/2 -1)
var3.test.exact[i] <- (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] )^2/ ( (alpha + n/2 -1)^2 * (alpha + n/2 -2) )
cov12.test.exact[i] <- n/(n+1) * intermed3[1,2] * (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1)
quant.theta1.test.freq[i,] <- c(qnst(0.025, 2*alpha + n, (intermed1 %*% y.test[i,])[1], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[1,1] ) ) ),
qnst(0.975, 2*alpha + n, (intermed1 %*% y.test[i,])[1], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[1,1] ) ) ) )
quant.theta2.test.freq[i,] <- c(qnst(0.025, 2*alpha + n, (intermed1 %*% y.test[i,])[2], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[2,2] ) ) ),
qnst(0.975, 2*alpha + n, (intermed1 %*% y.test[i,])[2], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[2,2] ) ) ) )
quant.theta3.test.freq[i,] <- c(1/qgamma(0.975,shape=alpha+n/2, rate=beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ), 1/qgamma(0.025,shape=alpha+n/2, rate=beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,]) )
}
reference_table = matrix(NA,nrow=p,ncol=6+n*3)
for(i in 1:p){
row_first = c(theta1.test.exact[i],theta2.test.exact[i],theta3.test.exact[i],var1.test.exact[i],var2.test.exact[i],var3.test.exact[i])
#print(row_first)
out = as.vector(t(cbind(design,as.numeric(y.test[i,]))))
#print(length(out))
reference_table[i,] = c(row_first,out)
}
write.table(reference_table[,1:6],paste0("/Users/ulf.mertens/Desktop/multi_gaussian/toy_examples/",ytest),row.names=F,col.names=F)
write.table(reference_table[,7:ncol(reference_table)],paste0("/Users/ulf.mertens/Desktop/multi_gaussian/toy_examples/",xtest),row.names=F,col.names=F)
# Regression toy example for ABC-RF method
rm(list=ls())
# 16-05-2018: Updated for Ulf Mertens to work with the last version of the package abcrf.
library(mvtnorm) # to simulate according to Multivariate Normal Distribution
library(abcrf) #ABC-RF
library(doParallel)
xtrain = 'xtrain.csv'
xtest = 'xtest.csv'
ytrain = 'ytrain.csv'
ytest = 'ytest.csv'
PATH = "/Users/ulf.mertens/Desktop/multi_gaussian/toy_examples/data/multiple_regression/"
# To compute quantiles according to the unstandardized Student distribution
qnst <- function(p, deg, loca, scale){
return( loca + scale*qt(p, df=deg))
}
n <- 100 # size of y
N <- 100000 # size of the training set
p <- 100 # size of testing set
nbrRes <- 10 # number of summary statistics we use
### We simulate a design matrix of size n x 2, denoted X in the paper
# We choose some parameters implied in the simulatation of the design matrix X, to have correlated columns
c <- 10#1
b <- 3#0.01
d <- -3#-0.01
#######################
#for(d in seq(-10,0,0.01)){
#   print( c(d,-b*d/sqrt((1+d^2)*(1+b^2))) )
# }
######################
# Simulate the design matrix X
set.seed(2) # reproducibility
design <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
h1 <- rnorm(1)
z <- rnorm(2)
design[i,1] <- (z[1]+b*h1)/sqrt(c)
design[i,2] <- (z[2]+d*h1)/sqrt(c)
}
cor(design[,1], design[,2])
var(design[,1])
var(design[,2])
apply(design,2,mean)
#####################################################
# Simulation of the reference table
# Parameters of the IG distribution
alpha <- 4
beta <- 3
##########################
# Training set
theta.train <- matrix(NA, nrow = N, ncol = 3) # to store the parameters
theta.train[,3] <- 1/rgamma(N,shape=alpha, rate=beta) # simulation of sigma2
# simulation of beta1 and beta2
for(i in 1:N){
theta.train[i,1:2] <- rmvnorm(1, rep(0,2), n*theta.train[i,3]*solve(crossprod(design)) )
}
# simulation of y
y.ref <- matrix(NA, nrow=N, ncol=n)
for(i in 1:N){
for(j in 1:n){
y.ref[i,j] <- design[j,] %*% theta.train[i,1:2] + rnorm( 1, 0, sqrt(theta.train[i,3]))
}
reference_table = matrix(NA,nrow=N,ncol=3+n*3)
for(i in 1:N){
row_first = c(theta.train[i,])
#print(row_first)
out = as.vector(t(cbind(design,as.numeric(y.ref[i,]))))
#print(length(out))
reference_table[i,] = c(row_first,out)
}
write.table(reference_table[,1:3],file.path(PATH,ytrain),row.names=F,col.names=F)
write.table(reference_table[,4:ncol(reference_table)],file.path(PATH,xtrain),row.names=F,col.names=F)
#write.table(reference_table,"/Users/ulf.mertens/Desktop/multi_gaussian/toy_examples/reftable_train.csv",row.names=F,col.names=F)
# computing the summary statistics
#summa.train <- matrix(NA, nrow=N, ncol=nbrRes)
#intermed <- solve(crossprod(design)) %*% t(design) # temporary variable
#for(i in 1:N){
#  summa.train[i,1:2] <- intermed %*% y.ref[i,]
#  res <- y.ref[i,] - design %*% summa.train[i,1:2]
#  summa.train[i,3] <- sum(res*res)
#  summa.train[i,4:7] <- c(cov(y.ref[i,], design[,1]),cov(y.ref[i,], design[,2]), cor(y.ref[i,], design[,1]), cor(y.ref[i,], design[,2]))
#  summa.train[i,8:10] <- c(mean(y.ref[i,]), median(y.ref[i,]), var(y.ref[i,]))
#}
#ref.training <- cbind(theta.train, summa.train)
#colnames(ref.training) <- c("beta1", "beta2", "sigma2", "mlBeta1", "mlBeta2","residu2","covyx1","covyx2","coryx1","coryx2","mean","median","var")
#####################################
# Testing set simulation
# as above
theta.test <- matrix(NA, nrow = p, ncol = 3)
theta.test[,3] <- 1/rgamma(p,shape=alpha,rate=beta)
for(i in 1:p){
theta.test[i,1:2] <- rmvnorm(1, rep(0,2), n*theta.test[i,3]*solve(crossprod(design)))
}
y.test <- matrix(NA, nrow=p, ncol=n)
for(i in 1:p){
for(j in 1:n){
y.test[i,j] <- design[j,] %*% theta.test[i,1:2] + rnorm(1,0,sqrt(theta.test[i,3]))
}
intermed1 <- n/(n+1)*solve(crossprod(design)) %*% t(design)
intermed2 <- design %*% solve(crossprod(design)) %*% t(design)
intermed3 <- solve(crossprod(design))
theta1.test.exact <- rep(NA, p)
theta2.test.exact <- rep(NA, p)
theta3.test.exact <- rep(NA, p)
var1.test.exact <- rep(NA, p)
var2.test.exact <- rep(NA, p)
var3.test.exact <- rep(NA, p)
cov12.test.exact <- rep(NA, p)
cov13.test.exact <- rep(0, p)
cov23.test.exact <- rep(0, p)
quant.theta1.test.freq <- matrix(NA, p, 2)
quant.theta2.test.freq <- matrix(NA, p, 2)
quant.theta3.test.freq <- matrix(NA, p, 2)
for(i in 1:p){
theta.test.exact <- intermed1 %*% y.test[i,]
theta1.test.exact[i] <- theta.test.exact[1]
theta2.test.exact[i] <- theta.test.exact[2]
theta3.test.exact[i] <- (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1)
var1.test.exact[i] <- n/(n+1) * intermed3[1,1] * (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] )/(alpha + n/2 -1)
var2.test.exact[i] <- n/(n+1) * intermed3[2,2] * (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] )/(alpha + n/2 -1)
var3.test.exact[i] <- (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] )^2/ ( (alpha + n/2 -1)^2 * (alpha + n/2 -2) )
cov12.test.exact[i] <- n/(n+1) * intermed3[1,2] * (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1)
quant.theta1.test.freq[i,] <- c(qnst(0.025, 2*alpha + n, (intermed1 %*% y.test[i,])[1], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[1,1] ) ) ),
qnst(0.975, 2*alpha + n, (intermed1 %*% y.test[i,])[1], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[1,1] ) ) ) )
quant.theta2.test.freq[i,] <- c(qnst(0.025, 2*alpha + n, (intermed1 %*% y.test[i,])[2], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[2,2] ) ) ),
qnst(0.975, 2*alpha + n, (intermed1 %*% y.test[i,])[2], sqrt( ( (beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ) / (alpha + n/2 -1) * n/(n+1) * intermed3[2,2] ) ) ) )
quant.theta3.test.freq[i,] <- c(1/qgamma(0.975,shape=alpha+n/2, rate=beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,] ), 1/qgamma(0.025,shape=alpha+n/2, rate=beta + 1/2*y.test[i,] %*% ( diag(1,n) - intermed2 ) %*% y.test[i,]) )
}
reference_table = matrix(NA,nrow=p,ncol=6+n*3)
for(i in 1:p){
row_first = c(theta1.test.exact[i],theta2.test.exact[i],theta3.test.exact[i],var1.test.exact[i],var2.test.exact[i],var3.test.exact[i])
#print(row_first)
out = as.vector(t(cbind(design,as.numeric(y.test[i,]))))
#print(length(out))
reference_table[i,] = c(row_first,out)
}
write.table(reference_table[,1:6],file.path(PATH,ytest),row.names=F,col.names=F)
write.table(reference_table[,7:ncol(reference_table)],file.path(PATH,xtest),row.names=F,col.names=F)
sessionInfo()
?mean
mean(x=c(1,2,3))
mean(c(1,2,3))
mean(c(1,NA,3))
mean(c(1,NA,3),na.rm=TRUE)
mean(c(1,NA,3),TRUE)
mean(na.rm=TRUE,x=c(1,2,3))
library(afex)
?aov_ez
aov_ez
mean
rm(list=ls())
setwd("~/Seafile/Uni/Kollegen/psychophysik")
if (!require("pacman")) install.packages("pacman")
required_packages = c("tidyverse","readbulk","broom","afex")
pacman::p_load(required_packages,update=F,character.only = T)
path = "bright3_neu"
q <- read_table2("bright3_neu/questionnaires.txt")[,1:21]
q$vp = gsub("\"", "", q$vp)
q[,1] = apply(q[,1],1,function(x) substr(paste0(x,'_stevens.dat'),2,16))
df <- read_bulk(directory = path,sep="",extension=".dat")
df = na.omit(df)
df = df %>% left_join(q,by = c("File" = "vp"))
df = df %>% mutate(cd = case_when(luminance == 16 ~ 1,  luminance == 23 ~ 1.8, luminance == 31 ~ 3.2,luminance == 41 ~ 5.7,
luminance == 68 ~ 17.9, luminance == 89 ~ 32, luminance == 116 ~ 57.2, luminance == 152 ~ 100))
df = df %>% mutate(bedingung = case_when(condition== "standard" ~ 1,
condition=="new" ~ 0))
df = df %>% mutate(Entfernung = case_when(luminance == 16 ~ 4,  luminance == 23 ~ 3, luminance == 31 ~ 2,luminance == 41 ~ 1,
luminance == 68 ~ 1, luminance == 89 ~ 2, luminance == 116 ~ 3, luminance == 152 ~ 4))
df = df %>% mutate(Level = case_when(luminance == 16 ~ 1,  luminance == 23 ~ 2, luminance == 31 ~ 3,luminance == 41 ~ 4,
luminance == 68 ~ 6, luminance == 89 ~ 7, luminance == 116 ~ 8, luminance == 152 ~ 9))
df = df %>% mutate(brightness_dichotom = ifelse(cd < 10,0,1))
df$brightness_rating = gsub("'","",df$brightness_rating)
df$brightness_rating = as.numeric(gsub(",",".",df$brightness_rating))
df$gender = gsub("'","",df$gender)
df$age = gsub("'","",df$age)
df$age = as.numeric(gsub(",",".",df$age))
df = df[df$brightness_rating!=0,]
# Demographie
summary(df$age)
df %>% distinct(File,.keep_all = T) %>% group_by(gender) %>% summarise(N=n(),
Min=min(age),
Max=max(age),
Mean=mean(age),
Sd=sd(age))
df %>% distinct(File,.keep_all = T) %>% count(student)
df %>% distinct(File,.keep_all = T) %>% filter(student==1) %>% count(psycho)
df %>% distinct(File,.keep_all = T) %>% count(condition)
df[,"brightness_rating_stevens"] = ifelse((df$condition=="new") & (df$brightness_dichotom==0),100/df$brightness_rating,df$brightness_rating)
df[,"brightness_rating"] = ifelse((df$condition=="standard") & (df$brightness_dichotom==0),10*(10/df$brightness_rating),df$brightness_rating)
df$logRating = log(df$brightness_rating_stevens)
df = df %>% mutate(levelCond = if_else(Level < 5, "<5", ">5"))
#### all log
ggplot(df,aes(x=cd,y=logRating))+
geom_boxplot(aes(fill=condition))
#### all
ggplot(df,aes(x=cd,y=brightness_rating_stevens))+
scale_x_continuous(breaks=sort(unique(df$cd)),limits=c(1,100))+
#scale_y_continuous(trans='log10',breaks=c(1,5,10,20,30),limits=c(1,30))+
#scale_y_continuous(breaks=c(10,20,30),limits=c(0,30))+
geom_point(aes(colour=condition,shape=condition))+
labs(x='cd/m^2',y='rating')+
geom_smooth(method="nls",
aes(colour=condition,linetype=condition),
formula=y~a*x^b+d,
se=FALSE) +
scale_colour_manual(values=c("darkgrey","black"),
name="method",
labels=c("sequential","standard"))+
guides(linetype=F,shape=F)+
xlab(expression(paste("cd/",m^2,sep="")))+
theme_classic()+
theme(axis.text.x=element_blank())+
theme(legend.position=c(0.2,0.9),legend.background = element_rect(color = "black"))
medianData = df %>% group_by(condition,cd) %>%
mutate(log_rating = median(logRating)) %>%
mutate(rating = median(brightness_rating_stevens)) %>%
distinct(condition,cd,.keep_all = T)
### ANOVA For vis
table(df$cd)
df$cd_factor = factor(df$cd,levels=c(1,1.8,3.2,5.7,17.9,32.0,57.2,100.0))
fit = aov_ez(dv="logRating",within='cd_factor',between="condition",id="File",data=df)
fit
grid = emmeans(fit,~cd_factor + condition)
kontrast = c(0,0,0,0,-1,-1,-1,-1,0,0,0,0,1,1,1,1)
kontrast_liste <- list(mED_vs_wM = kontrast)
contrast(grid, kontrast_liste)
emmip(fit,condition ~cd_factor,CIs=F) +theme_classic()
emmip(fit,~condition,CIs=T)
ggplot(medianData,aes(x=cd,y=rating))+
scale_x_continuous(breaks=sort(unique(medianData$cd)),limits=c(1,100))+
#scale_y_continuous(trans='log10',breaks=c(1,5,10,20,30),limits=c(1,30))+
#scale_y_continuous(breaks=c(10,20,30),limits=c(0,30))+
geom_point(aes(colour=condition,shape=condition))+
labs(x='cd/m^2',y='rating')+
geom_smooth(method="nls",
aes(colour=condition,linetype=condition),
formula=y~a*x^b+d,
se=FALSE) +
scale_colour_manual(values=c("darkgrey","black"),
name="method",
labels=c("sequential","standard"))+
guides(linetype=F,shape=F)+
xlab(expression(paste("cd/",m^2,sep="")))+
theme_classic()+
theme(axis.text.x=element_blank())+
theme(legend.position=c(0.2,0.9),legend.background = element_rect(color = "black"))
(fit01 = nls(rating ~ b0*cd^b1+b2 , data=medianData[medianData$condition=="standard",]))
(fit02 = nls(rating ~ b0*cd^b1+b2 , data=medianData[medianData$condition=="new",]))
ggplot(medianData,aes(x=log(cd),y=log_rating))+
#scale_x_continuous(breaks=sort(unique(df$cd)),limits=c(1,100))+
#scale_y_continuous(trans='log10',breaks=c(1,5,10,20,30),limits=c(1,30))+
#scale_y_continuous(breaks=c(10,20,30),limits=c(0,30))+
geom_point(aes(colour=condition,shape=condition))+
labs(x='log(cd/m^2)',y='log(rating)')+
geom_smooth(aes(colour=condition),method='lm',se=F)+
scale_colour_manual(values=c("darkgrey","black"),
name="method",
labels=c("sequential","standard"))+
guides(linetype=F,shape=F)+
xlab(expression(paste("log(cd/",m^2,')',sep="")))+
#expand_limits(x=0,y=0)+
theme_classic()+
theme(axis.text.x=element_blank())+
theme(legend.position=c(0.1,0.9),legend.background = element_rect(color = "black"))
ggplot(df,aes(x=cd,y=brightness_rating_stevens)) +
geom_point(aes(colour=condition,shape=condition))+
stat_smooth(method = 'nls', formula = y ~ b0*x^b1 + b2, aes(colour=condition),se = FALSE, method.args = list(start = c(b0=1,b1=1, b2 = 1))) +
theme_classic()
ggplot(df,aes(x=cd,y=logRating)) +
geom_boxplot(aes(fill=condition))+
labs(y='log(rating)',x='cd/m^2')+
scale_fill_manual(values=c("darkgrey","white"),
name="method",
labels=c("sequential","standard"))+
xlab(expression(paste("cd/",m^2,sep="")))+
theme_classic()+
theme(legend.position=c(0.1,0.9),legend.background = element_rect(color = "black"))
## all
ggplot(df,aes(x=log(cd),y=logRating)) +
geom_point(aes(colour=condition))+
facet_grid(~levelCond,scales="free") +
stat_smooth(method = 'lm', formula = y ~ x, aes(colour=condition),se = FALSE)+
theme_classic()
## aggregated
ggplot(medianData,aes(x=log(cd),y=log_rating)) +
geom_point(aes(colour=condition))+
facet_grid(~levelCond,scales="free") +
stat_smooth(method = 'lm', formula = y ~ x, aes(colour=condition),se = FALSE)+
theme_classic()
aggData = df %>% group_by(condition,cd,File) %>%
mutate(rating = median(brightness_rating_stevens)) %>%
distinct(condition,cd,File,.keep_all = T)
## all
expon_nls = aggData %>%
#filter(Level < 5) %>%
group_by(condition,File) %>%
do(broom::glance(minpack.lm::nlsLM(rating ~ a*cd^b , data = .))) %>%
mutate(model='nls')
expon_lm = aggData %>%
#filter(Level < 5) %>%
group_by(condition,File) %>%
do(broom::glance(lm(rating ~ cd, data = .))) %>%
mutate(model='lm')
expon_tot = bind_rows(expon_nls,expon_lm)
ggplot(expon_tot,aes(x=condition,y=AIC))+geom_boxplot(aes(fill=model))+theme_classic()
aov_ez(dv='AIC',between='condition',within='model',data=expon_tot,id='File')
expon_test1 = aggData %>%
group_by(condition,File) %>%
nest() %>%
mutate(fit_nls = purrr::map(data, ~ minpack.lm::nlsLM(rating ~ a*cd^b ,data=.)),
fit_lm = purrr::map(data, ~ lm(rating ~ cd,data=.)))
anova_list = expon_test1 %>%
group_by(condition, File) %>%
do(bic=BIC(.$fit_nls[[1]]))
p_vals_anova = unlist(lapply(anova_list,function(x) x$"Pr(>F)"[2]))
test = aggData %>% group_by(condition,File) %>% summarise(Mean=mean(rating)) %>% ungroup()
test =test %>% mutate(p_vals = p_vals_anova)
ggplot(test,aes(x=condition,y=p_vals))+geom_boxplot()+scale_y_continuous(trans='log10')
test$p_vals_log = log(test$p_vals)
ttestIS(vars='p_vals_log',group='condition',data=test)
fit = aov_ez(dv='AIC',within='model',between='condition',id='File',data=expon_tot)
########## bayesian part
library(brms)
prior1 <- prior(normal(0, 5), nlpar = "a") + prior(normal(1, 1), nlpar = "b")
fit1 <- brm(bf(rating ~ a * cd^b, a + b ~ 1, nl = TRUE),data = aggData,prior = prior1)
library(brms)
prior1 <- prior(normal(0, 5), nlpar = "a") + prior(normal(1, 1), nlpar = "b")
fit1 <- brm(bf(rating ~ a * cd^b, a + b ~ 1, nl = TRUE),data = aggData,prior = prior1)
fit1
?bf
fit1 <- brm(bf(rating ~ a * cd^b + (a|File), a + b ~ 1, nl = TRUE),data = aggData,prior = prior1)
?brm
fit1 <- brm(bf(rating ~ a * cd^b + (a|File), a~(1|File), b ~(1|File), nl = TRUE),data = aggData,prior = prior1)
fit1 <- brm(bf(rating ~ a * cd^b , a~(1|File), b ~(1|File), nl = TRUE),data = aggData,prior = prior1)
fit1
prior1 <- prior(normal(0, 5), nlpar = "a") + prior(normal(1, 1), nlpar = "b")
fit1 <- brm(bf(rating ~ a * cd^b , a~(1+a|File), b ~(1+b|File), nl = TRUE),data = aggData,prior = prior1)
View(aggData)
prior1 <- prior(normal(0, 5), nlpar = "a") + prior(normal(1, 0.5), nlpar = "b")
fit1 <- brm(bf(rating ~ a * cd^b , a~(1|File), b ~(1|File), nl = TRUE),data = aggData[aggData$condition=='new',],prior = prior1)
fit2 <- brm(bf(rating ~ a + b*cd , a~(1|File), b ~(1|File), nl = F),data = aggData[aggData$condition=='new',],prior = prior1)
LOO(fit1,fit2)
fit2 <- brm(rating ~ cd + (1+cd|File), data = aggData[aggData$condition=='new',],prior = prior1)
fit2 <- brm(rating ~ cd + (1+cd|File), data = aggData[aggData$condition=='new',])
LOO(fit1,fit2)
LOO(fit1,fit2,k=10)
LOO(fit1,fit2,K=10)
prior1 <- prior(normal(0, 5), nlpar = "a") + prior(normal(1, 0.5), nlpar = "b")
fit1 <- brm(bf(brightness_rating_stevens ~ a * cd^b , a~(1|File), b ~(1|File), nl = TRUE),data = df[df$condition=='new',],prior = prior1)
fit2 <- brm(brightness_rating_stevens ~ cd + (1+cd|File), data = df[df$condition=='new',])
LOO(fit1,fit2)
prior1 <- prior(normal(0, 5), nlpar = "a") + prior(normal(1, 0.5), nlpar = "b")
fit1 <- brm(bf(brightness_rating_stevens ~ a * cd^b , a~(1|File), b ~(1|File), nl = TRUE),data = df[df$condition=='standard',],prior = prior1)
fit2 <- brm(brightness_rating_stevens ~ cd + (1+cd|File), data = df[df$condition=='standard',])
LOO(fit1,fit2)
?LOO
install.packages('nlme')
install.packages("nlme")
library(nlme)
fm1=nlsList(rating~ a * cd^b,data=data1, start=list(a=50,b=40))
model1=nlme(fm3,data1, fixed=list(a~1,b~1), random=list(b~1|File,a~1|File))
fm1=nlme::nlsList(rating~ a * cd^b,data=data1, start=list(a=50,b=40))
fm1=nlme::nlsList(rating~ a * cd^b,data=df, start=list(a=0,b=0.5))
fm1=nlme::nlsList(rating~ a * cd^b + (1+a|File),data=df, start=list(a=0,b=0.5))
fm1=nlme::nlsList(rating~ a * cd^b,data=df, start=list(a=0,b=0.5))
fm1=nlme::nlsList(rating~ a * cd^b,data=df, start=c(a=0,b=0.5))
?nlme::nlsList
fm1=nlme::nlsList(rating~ a * cd^b,data=df, start=c(a=0,b=0.5),groups= ~File)
model1=nlme(rating~ a * cd^b,data1, fixed=list(a~1,b~1), random=list(b~1|File,a~1|File))
model1=nlme::nlme(rating~ a * cd^b,data1, fixed=list(a~1,b~1), random=list(b~1|File,a~1|File))
model1=nlme::nlme(rating~ a * cd^b,data=df, fixed=list(a~1,b~1), random=list(b~1|File,a~1|File))
library(nlme)
mod <- function(param, cd){
f = param[0] * cd^param[1]
return(f)
}
model1=nlme::nlme(rating~ mod(param,cd),data=df, fixed=list(a~1,b~1), random=list(b~1|File,a~1|File))
model1=nlme::nlme(rating ~ mod(param,cd),data=df, fixed=list(a~1,b~1), random=list(b~1|File,a~1|File))
?nlme::nlme
power.f = deriv(~a*cd^b, namevec=c('a', 'b'), function.arg=c('cd','a','b'))
fit.nlmer = nlmer(rating ~ power.f(cd, a, b) ~ a|id, start=list(nlpars=c(a=0, b=0.5)), data=df)
model1=nlme::nlme(brightness_rating_stevens ~ mod(param,cd),data=df, fixed=list(a~1,b~1), random=list(b~1|File,a~1|File))
fit.nlmer = nlmer(brightness_rating_stevens ~ power.f(cd, a, b) ~ a|id, start=list(nlpars=c(a=0, b=0.5)), data=df)
fit.nlmer = nlmer(brightness_rating_stevens ~ power.f(cd, a, b) ~ a|File, start=list(nlpars=c(a=0, b=0.5)), data=df)
fit.nlmer = nlmer(brightness_rating_stevens ~ power.f(cd, a, b), start=list(nlpars=c(a=0, b=0.5)), data=df)
?bf
df = df %>% select(File,cd,brightness_rating_stevens)
lapply(strsplit(df$File,'_'),function(x) x[1])
lapply(strsplit(df$File,'_'),function(x) x[1][1])
unlist(lapply(strsplit(df$File,'_'),function(x) x[1]))
df$File = unlist(lapply(strsplit(df$File,'_'),function(x) x[1]))
View(df)
names(df) = c('File','cd','y')
View(df)
dput(df)
df = data.frame(df)
dput(df)
View(df)
fit.nlmer = nlmer(brightness_rating_stevens ~ power.f(cd, a, b) ~ (a|File), start=list(nlpars=c(a=0, b=0.5)), data=df)
setwd("~/Desktop/multi_gaussian/toy_examples/multivariate_normal/data")
install.packages('abcrf')
install.packages('Metrics')
# Read in training data
data_train = read.table("./dataframes/X_train_first.csv", sep = ";", header=TRUE)
# Read in training data
data_train = read.table("/dataframes/X_train_rf.csv", sep = ";", header=TRUE)
# Read in training data
data_train = read.table("./dataframes/X_train_rf.csv", sep = ";", header=TRUE)
rm(list=ls())
data_train = read.table("./dataframes/X_train_rf.csv", sep = ";", header=TRUE)
params_train = read.table("./dataframes/y_train_rf.csv", sep = ";", header=TRUE)
# Read in test-data
data_test = read.table("./dataframes/X_test_rf.csv", sep = ";", header=TRUE)
params_test = read.table("./dataframes/y_test_rf.csv", sep = ";", header=TRUE)
train_df = data_train
train_df$mu1 = params_train$mean1
rf = regAbcrf(mu1 ~ ., train_df, ntree=500)
pred_mu1 = predict(rf, data_test, train_df)
#install.packages('abcrf')
#install.packages('Metrics')
library(abcrf)
library(Metrics)
train_df = data_train
train_df$mu1 = params_train$mean1
rf = regAbcrf(mu1 ~ ., train_df, ntree=500)
library(doParallel)
rf = regAbcrf(mu1 ~ ., train_df, ntree=500,paral=T)
#install.packages('abcrf')
#install.packages('Metrics')
library(abcrf)
library(Metrics)
library(doParallel)
rm(list=ls())
setwd("~/Desktop/multi_gaussian/toy_examples/multivariate_normal/data")
# Read in training data
data_train = read.table("./dataframes/X_train_rf.csv", sep = ";", header=TRUE)
params_train = read.table("./dataframes/y_train_rf.csv", sep = ";", header=TRUE)
# Read in test-data
data_test = read.table("./dataframes/X_test_rf.csv", sep = ";", header=TRUE)
params_test = read.table("./dataframes/y_test_rf.csv", sep = ";", header=TRUE)
# Train four random forests for each parameter and test on common test set
# Note - we overwrite the rf regressor for each parameter, since it is
# very memory expensive to keep all four in-memory (due to large dataset)
# mu1
train_df = data_train
train_df$mu1 = params_train$mean1
rf = regAbcrf(mu1 ~ ., train_df, ntree=500,paral=T)
